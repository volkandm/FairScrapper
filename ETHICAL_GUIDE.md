# FairScrapper Ethical Usage Guide

## ğŸ¯ Etik Web Scraping Pratikleri

FairScrapper, etik ve yasal web scraping iÃ§in tasarlanmÄ±ÅŸtÄ±r. Bu rehber, sorumlu kullanÄ±m iÃ§in Ã¶nemli kurallarÄ± iÃ§erir.

## âš–ï¸ Yasal Durum

### âœ… Genellikle Yasal Olan KullanÄ±mlar:

1. **Halka AÃ§Ä±k Veriler:**
   - RSS feed'leri
   - API'ler (rate limit'lere uygun)
   - Creative Commons lisanslÄ± iÃ§erik
   - AÃ§Ä±k veri setleri

2. **Kendi Siteniz:**
   - Kendi web sitenizi test etme
   - Performans izleme
   - SEO analizi

3. **EÄŸitim ve AraÅŸtÄ±rma:**
   - Akademik araÅŸtÄ±rmalar
   - Ã–ÄŸrenme amaÃ§lÄ± kullanÄ±m
   - Teknik deneyler

### âŒ Yasal Olmayan KullanÄ±mlar:

1. **Telif HakkÄ± Ä°hlali:**
   - Ã–zel iÃ§eriÄŸi izinsiz kopyalama
   - Ticari amaÃ§la iÃ§erik Ã§alma
   - LisanssÄ±z kullanÄ±m

2. **KiÅŸisel Veri:**
   - GDPR/CCPA ihlali
   - RÄ±za olmadan kiÅŸisel bilgi toplama
   - Hassas veri iÅŸleme

3. **KullanÄ±m ÅartlarÄ± Ä°hlali:**
   - Site ToS'unu ihlal etme
   - Hesap oluÅŸturma yasaÄŸÄ±
   - Otomatik eriÅŸim yasaÄŸÄ±

## ğŸ›¡ï¸ Etik KullanÄ±m KurallarÄ±

### 1. **robots.txt DosyasÄ±na Uyun**
```bash
# Ã–rnek robots.txt kontrolÃ¼
User-agent: *
Disallow: /private/
Allow: /public/
```

### 2. **Rate Limiting UygulayÄ±n**
- Makul bekleme sÃ¼releri (1-5 saniye)
- Sunucuya yÃ¼k bindirmeyin
- Peak saatlerde dikkatli olun

### 3. **Åeffaf User-Agent KullanÄ±n**
```python
# Ã–rnek ÅŸeffaf user agent
USER_AGENT = "FairScrapper/1.0 (+https://github.com/your-repo)"
```

### 4. **Veri KullanÄ±mÄ±**
- Sadece gerekli verileri toplayÄ±n
- KiÅŸisel bilgileri filtreleyin
- Veri saklama sÃ¼relerini belirleyin

## ğŸ“‹ Best Practices

### âœ… YapÄ±lmasÄ± Gerekenler:

1. **Ã–nceden Ä°zin AlÄ±n:**
   - Site sahiplerine danÄ±ÅŸÄ±n
   - API dokÃ¼mantasyonunu okuyun
   - KullanÄ±m ÅŸartlarÄ±nÄ± kontrol edin

2. **DÃ¼zenli Kontroller:**
   - robots.txt gÃ¼ncellemelerini takip edin
   - Site deÄŸiÅŸikliklerini izleyin
   - Rate limit'leri kontrol edin

3. **Veri Kalitesi:**
   - DoÄŸru veri toplayÄ±n
   - HatalarÄ± dÃ¼zeltin
   - KaynaklarÄ± belirtin

### âŒ YapÄ±lmamasÄ± Gerekenler:

1. **AÅŸÄ±rÄ± YÃ¼k Bindirme:**
   - Ã‡ok hÄ±zlÄ± istekler
   - Paralel baÄŸlantÄ±lar
   - Sunucu kaynaklarÄ±nÄ± tÃ¼ketme

2. **Gizli Scraping:**
   - Sahte user agent
   - IP gizleme (yasal olmayan durumlarda)
   - Bot tespitinden kaÃ§Ä±nma

3. **Veri KÃ¶tÃ¼ye KullanÄ±mÄ±:**
   - Spam gÃ¶nderme
   - Rekabet analizi
   - Ticari avantaj saÄŸlama

## ğŸ”§ FairScrapper GÃ¼venlik Ã–zellikleri

### 1. **Otomatik Rate Limiting**
```python
# VarsayÄ±lan bekleme sÃ¼releri
DEFAULT_WAIT_TIME = 5000  # 5 saniye
MAX_RETRIES = 3
```

### 2. **Proxy Rotasyonu**
- YÃ¼k daÄŸÄ±tÄ±mÄ±
- Sunucu dostu yaklaÅŸÄ±m
- Otomatik hata yÃ¶netimi

### 3. **Åeffaf Logging**
- TÃ¼m aktiviteleri kaydetme
- Hata raporlama
- Performans izleme

## ğŸ“ Yasal Destek

### Kaynaklar:
- [Web Scraping Legal Guide](https://www.scrapingbee.com/blog/web-scraping-legal/)
- [GDPR Compliance](https://gdpr.eu/)
- [robots.txt Standard](https://www.robotstxt.org/)

### Ã–neriler:
1. Yasal danÄ±ÅŸmanlÄ±k alÄ±n
2. Site sahipleriyle iletiÅŸime geÃ§in
3. KullanÄ±m ÅŸartlarÄ±nÄ± dikkatle okuyun
4. Veri koruma yasalarÄ±nÄ± Ã¶ÄŸrenin

## ğŸ¯ SonuÃ§

FairScrapper, etik ve yasal web scraping iÃ§in tasarlanmÄ±ÅŸtÄ±r. Bu rehberi takip ederek sorumlu kullanÄ±m saÄŸlayabilirsiniz.

**UnutmayÄ±n:** Bu araÃ§ sadece eÄŸitim ve araÅŸtÄ±rma amaÃ§lÄ±dÄ±r. KullanÄ±cÄ±lar kendi yasal sorumluluklarÄ±nÄ± Ã¼stlenir.

---

*Bu rehber genel bilgi amaÃ§lÄ±dÄ±r ve yasal tavsiye niteliÄŸi taÅŸÄ±maz. Spesifik durumlar iÃ§in yasal danÄ±ÅŸmanlÄ±k almanÄ±z Ã¶nerilir.*
